{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load genFeat_counting_feat.py\n",
    "\n",
    "\"\"\"\n",
    "__file__\n",
    "\n",
    "    genFeat_counting_feat.py\n",
    "\n",
    "__description__\n",
    "\n",
    "    This file generates the following features for each run and fold, \n",
    "    and for the entire training and testing set.\n",
    "\n",
    "        1. Basic Counting Features\n",
    "            \n",
    "            1. Count of n-gram in query/title/description\n",
    "\n",
    "            2. Count & Ratio of Digit in query/title/description\n",
    "\n",
    "            3. Count & Ratio of Unique n-gram in query/title/description\n",
    "\n",
    "        2. Intersect Counting Features\n",
    "\n",
    "            1. Count & Ratio of a's n-gram in b's n-gram\n",
    "\n",
    "        3. Intersect Position Features\n",
    "\n",
    "            1. Statistics of Positions of a's n-gram in b's n-gram\n",
    "\n",
    "            2. Statistics of Normalized Positions of a's n-gram in b's n-gram\n",
    "\n",
    "__author__\n",
    "\n",
    "    Chenglong Chen < c.chenglong@gmail.com >\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import ngram\n",
    "import dill\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nlp_utils import stopwords, english_stemmer, stem_tokens\n",
    "from feat_utils import try_divide, dump_feat_name\n",
    "sys.path.append(\"../\")\n",
    "from param_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_list(target, obs):\n",
    "    \"\"\"\n",
    "        Get the list of positions of obs in target\n",
    "    \"\"\"\n",
    "    pos_of_obs_in_target = [0]\n",
    "    if len(obs) != 0:\n",
    "        pos_of_obs_in_target = [j for j,w in enumerate(obs, start=1) if w in target]\n",
    "        if len(pos_of_obs_in_target) == 0:\n",
    "            pos_of_obs_in_target = [0]\n",
    "    return pos_of_obs_in_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## Pre-process data ##\n",
    "######################\n",
    "token_pattern = r\"(?u)\\b\\w\\w+\\b\"##匹配含2个或2个以上字符的单词\n",
    "#token_pattern = r'\\w{1,}'\n",
    "#token_pattern = r\"\\w+\"\n",
    "#token_pattern = r\"[\\w']+\"\n",
    "def preprocess_data(line,\n",
    "                    token_pattern=token_pattern,\n",
    "                    exclude_stopword=config.cooccurrence_word_exclude_stopword,\n",
    "                    encode_digit=False):\n",
    "#     token_pattern = re.compile(token_pattern, flags = re.UNICODE | re.LOCALE)\n",
    "    token_pattern = re.compile(token_pattern, flags = re.UNICODE)\n",
    "    ## tokenize\n",
    "    tokens = [x.lower() for x in token_pattern.findall(line)]\n",
    "    ## stem\n",
    "    tokens_stemmed = stem_tokens(tokens, english_stemmer)\n",
    "    if exclude_stopword:\n",
    "        tokens_stemmed = [x for x in tokens_stemmed if x not in stopwords]\n",
    "    return tokens_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate unigram\n"
     ]
    }
   ],
   "source": [
    "def unigram(df):\n",
    "    ## unigram\n",
    "    print (\"generate unigram\")\n",
    "    df[\"query_unigram\"] = list(df.apply(lambda x: preprocess_data(x[\"query\"]), axis=1))\n",
    "    df[\"title_unigram\"] = list(df.apply(lambda x: preprocess_data(x[\"product_title\"]), axis=1))\n",
    "    df[\"description_unigram\"] = list(df.apply(lambda x: preprocess_data(x[\"product_description\"]), axis=1))\n",
    "unigram(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate bigram\n"
     ]
    }
   ],
   "source": [
    "def bigram(df):\n",
    "    ## bigram\n",
    "    print (\"generate bigram\")\n",
    "    join_str = \"_\"\n",
    "    df[\"query_bigram\"] = list(df.apply(lambda x: ngram.getBigram(x[\"query_unigram\"], join_str), axis=1))\n",
    "    df[\"title_bigram\"] = list(df.apply(lambda x: ngram.getBigram(x[\"title_unigram\"], join_str), axis=1))\n",
    "    df[\"description_bigram\"] = list(df.apply(lambda x: ngram.getBigram(x[\"description_unigram\"], join_str), axis=1))\n",
    "bigram(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate trigram\n"
     ]
    }
   ],
   "source": [
    "def trigram(df):\n",
    "    ## trigram\n",
    "    print (\"generate trigram\")\n",
    "    join_str = \"_\"\n",
    "    df[\"query_trigram\"] = list(df.apply(lambda x: ngram.getTrigram(x[\"query_unigram\"], join_str), axis=1))\n",
    "    df[\"title_trigram\"] = list(df.apply(lambda x: ngram.getTrigram(x[\"title_unigram\"], join_str), axis=1))\n",
    "    df[\"description_trigram\"] = list(df.apply(lambda x: ngram.getTrigram(x[\"description_unigram\"], join_str), axis=1))\n",
    "trigram(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = [\"query\", \"title\", \"description\"]\n",
    "grams = [\"unigram\", \"bigram\", \"trigram\"]\n",
    "count_digit = lambda x: sum([1. for w in x if w.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate word counting features\n"
     ]
    }
   ],
   "source": [
    "def countWordandDigit(df):\n",
    "    '''\n",
    "    统计gram数，unique gram数，比例，数值的数量\n",
    "    '''\n",
    "    ################################\n",
    "    ## word count and digit count ##\n",
    "    ################################\n",
    "    print (\"generate word counting features\")\n",
    "    for feat_name in feat_names:\n",
    "        for gram in grams:\n",
    "            ## word count\n",
    "            df[\"count_of_%s_%s\"%(feat_name,gram)] = list(df.apply(lambda x: len(x[feat_name+\"_\"+gram]), axis=1))\n",
    "            df[\"count_of_unique_%s_%s\"%(feat_name,gram)] = list(df.apply(lambda x: len(set(x[feat_name+\"_\"+gram])), axis=1))\n",
    "            df[\"ratio_of_unique_%s_%s\"%(feat_name,gram)] = list(map(try_divide, df[\"count_of_unique_%s_%s\"%(feat_name,gram)], df[\"count_of_%s_%s\"%(feat_name,gram)]))\n",
    "\n",
    "        ## digit count\n",
    "        df[\"count_of_digit_in_%s\"%feat_name] = list(df.apply(lambda x: count_digit(x[feat_name+\"_unigram\"]), axis=1))\n",
    "        df[\"ratio_of_digit_in_%s\"%feat_name] = list(map(try_divide, df[\"count_of_digit_in_%s\"%feat_name], df[\"count_of_%s_unigram\"%(feat_name)]))\n",
    "\n",
    "    ## description missing indicator 是否没有description\n",
    "    df[\"description_missing\"] = list(df.apply(lambda x: int(x[\"description_unigram\"] == \"\"), axis=1))\n",
    "countWordandDigit(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate intersect word counting features\n"
     ]
    }
   ],
   "source": [
    "def countIntersectWord(df):\n",
    "    ##############################\n",
    "    ## intersect word count ##\n",
    "    ##############################\n",
    "    print (\"generate intersect word counting features\")\n",
    "    #### unigram\n",
    "    for gram in grams:\n",
    "        for obs_name in feat_names:\n",
    "            for target_name in feat_names:\n",
    "                if target_name != obs_name:\n",
    "                    ## query\n",
    "                    df[\"count_of_%s_%s_in_%s\"%(obs_name,gram,target_name)] = list(df.apply(lambda x: sum([1. for w in x[obs_name+\"_\"+gram] if w in set(x[target_name+\"_\"+gram])]), axis=1))\n",
    "                    df[\"ratio_of_%s_%s_in_%s\"%(obs_name,gram,target_name)] = list(map(try_divide, df[\"count_of_%s_%s_in_%s\"%(obs_name,gram,target_name)], df[\"count_of_%s_%s\"%(obs_name,gram)]))\n",
    "\n",
    "        ## some other feat\n",
    "        df[\"title_%s_in_query_div_query_%s\"%(gram,gram)] = list(map(try_divide, df[\"count_of_title_%s_in_query\"%gram], df[\"count_of_query_%s\"%gram]))\n",
    "        df[\"title_%s_in_query_div_query_%s_in_title\"%(gram,gram)] = list(map(try_divide, df[\"count_of_title_%s_in_query\"%gram], df[\"count_of_query_%s_in_title\"%gram]))\n",
    "        df[\"description_%s_in_query_div_query_%s\"%(gram,gram)] = list(map(try_divide, df[\"count_of_description_%s_in_query\"%gram], df[\"count_of_query_%s\"%gram]))\n",
    "        df[\"description_%s_in_query_div_query_%s_in_description\"%(gram,gram)] = list(map(try_divide, df[\"count_of_description_%s_in_query\"%gram], df[\"count_of_query_%s_in_description\"%gram]))\n",
    "countIntersectWord(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate intersect word position features\n"
     ]
    }
   ],
   "source": [
    "def extract_feat(df):   \n",
    "\n",
    "    ######################################\n",
    "    ## intersect word position feat ##\n",
    "    ######################################\n",
    "    print (\"generate intersect word position features\")\n",
    "    for gram in grams:\n",
    "        for target_name in feat_names:\n",
    "            for obs_name in feat_names:\n",
    "                if target_name != obs_name:\n",
    "                    pos = list(df.apply(lambda x: get_position_list(x[target_name+\"_\"+gram], obs=x[obs_name+\"_\"+gram]), axis=1))\n",
    "                    ## stats feat on pos\n",
    "                    df[\"pos_of_%s_%s_in_%s_min\" % (obs_name, gram, target_name)] = map(np.min, pos)\n",
    "                    df[\"pos_of_%s_%s_in_%s_mean\" % (obs_name, gram, target_name)] = map(np.mean, pos)\n",
    "                    df[\"pos_of_%s_%s_in_%s_median\" % (obs_name, gram, target_name)] = map(np.median, pos)\n",
    "                    df[\"pos_of_%s_%s_in_%s_max\" % (obs_name, gram, target_name)] = map(np.max, pos)\n",
    "                    df[\"pos_of_%s_%s_in_%s_std\" % (obs_name, gram, target_name)] = map(np.std, pos)\n",
    "                    ## stats feat on normalized_pos\n",
    "                    df[\"normalized_pos_of_%s_%s_in_%s_min\" % (obs_name, gram, target_name)] = map(try_divide, df[\"pos_of_%s_%s_in_%s_min\" % (obs_name, gram, target_name)], df[\"count_of_%s_%s\" % (obs_name, gram)])\n",
    "                    df[\"normalized_pos_of_%s_%s_in_%s_mean\" % (obs_name, gram, target_name)] = map(try_divide, df[\"pos_of_%s_%s_in_%s_mean\" % (obs_name, gram, target_name)], df[\"count_of_%s_%s\" % (obs_name, gram)])\n",
    "                    df[\"normalized_pos_of_%s_%s_in_%s_median\" % (obs_name, gram, target_name)] = map(try_divide, df[\"pos_of_%s_%s_in_%s_median\" % (obs_name, gram, target_name)], df[\"count_of_%s_%s\" % (obs_name, gram)])\n",
    "                    df[\"normalized_pos_of_%s_%s_in_%s_max\" % (obs_name, gram, target_name)] = map(try_divide, df[\"pos_of_%s_%s_in_%s_max\" % (obs_name, gram, target_name)], df[\"count_of_%s_%s\" % (obs_name, gram)])\n",
    "                    df[\"normalized_pos_of_%s_%s_in_%s_std\" % (obs_name, gram, target_name)] = map(try_divide, df[\"pos_of_%s_%s_in_%s_std\" % (obs_name, gram, target_name)] , df[\"count_of_%s_%s\" % (obs_name, gram)])\n",
    "extract_feat(dfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## Load Data ##\n",
    "###############\n",
    "## load data\n",
    "with open(config.processed_train_data_path, \"rb\") as f:\n",
    "    dfTrain = dill.load(f)\n",
    "with open(config.processed_test_data_path, \"rb\") as f:\n",
    "    dfTest = dill.load(f)\n",
    "## load pre-defined stratified k-fold index\n",
    "with open(\"%s/stratifiedKFold.%s1.pkl\" % (config.data_folder, config.stratified_label), \"rb\") as f:\n",
    "        skf = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>median_relevance</th>\n",
       "      <th>relevance_variance</th>\n",
       "      <th>index</th>\n",
       "      <th>median_relevance_1</th>\n",
       "      <th>median_relevance_2</th>\n",
       "      <th>median_relevance_3</th>\n",
       "      <th>median_relevance_4</th>\n",
       "      <th>qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bridal shower decorations</td>\n",
       "      <td>accent pillow with heart design - red/black</td>\n",
       "      <td>red satin accent pillow embroidered with a hea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      query                                product_title  \\\n",
       "0   1  bridal shower decorations  accent pillow with heart design - red/black   \n",
       "\n",
       "                                 product_description  median_relevance  \\\n",
       "0  red satin accent pillow embroidered with a hea...                 1   \n",
       "\n",
       "   relevance_variance  index  median_relevance_1  median_relevance_2  \\\n",
       "0                 0.0      0                   1                   0   \n",
       "\n",
       "   median_relevance_3  median_relevance_4  qid  \n",
       "0                   0                   0   31  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Generate counting features...\n",
      "For cross-validation...\n",
      "Run: 1, Fold: 1\n",
      "Run: 1, Fold: 2\n",
      "Run: 1, Fold: 3\n",
      "Run: 2, Fold: 1\n",
      "Run: 2, Fold: 2\n",
      "Run: 2, Fold: 3\n",
      "Run: 3, Fold: 1\n",
      "Run: 3, Fold: 2\n",
      "Run: 3, Fold: 3\n",
      "Done.\n",
      "For training and testing...\n",
      "generate intersect word position features\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('count_of_query_unigram_unigram', 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   2565\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2566\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2567\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-a92108007d1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s/All\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeat_folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m## use full version for X_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mextract_feat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeat_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeat_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-e347c3a1acf3>\u001b[0m in \u001b[0;36mextract_feat\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mobs_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeat_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtarget_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mobs_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                     \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_position_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgram\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgram\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                     \u001b[1;31m## stats feat on pos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pos_of_%s_%s_in_%s_min\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mobs_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   4875\u001b[0m                         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4876\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4877\u001b[1;33m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[0;32m   4878\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4879\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4971\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4972\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4973\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4974\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4975\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-e347c3a1acf3>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mobs_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeat_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtarget_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mobs_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                     \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_position_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgram\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgram\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                     \u001b[1;31m## stats feat on pos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pos_of_%s_%s_in_%s_min\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mobs_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   2572\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2573\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2574\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2575\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2576\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   2558\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2559\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 2560\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   2561\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2562\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('count_of_query_unigram_unigram', 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "## file to save feat names\n",
    "feat_name_file = \"%s/counting.feat_name\" % config.feat_folder\n",
    "\n",
    "\n",
    "#######################\n",
    "## Generate Features ##\n",
    "#######################\n",
    "print(\"==================================================\")\n",
    "print(\"Generate counting features...\")\n",
    "\n",
    "\n",
    "# extract_feat(dfTrain)\n",
    "feat_names = [\n",
    "    name for name in dfTrain.columns \\\n",
    "        if \"count\" in name \\\n",
    "        or \"ratio\" in name \\\n",
    "        or \"div\" in name \\\n",
    "        or \"pos_of\" in name\n",
    "]\n",
    "feat_names.append(\"description_missing\")\n",
    "\n",
    "\n",
    "print(\"For cross-validation...\")\n",
    "for run in range(config.n_runs):\n",
    "    ## use 33% for training and 67 % for validation\n",
    "    ## so we switch trainInd and validInd\n",
    "    for fold, (validInd, trainInd) in enumerate(skf[run]):\n",
    "        print(\"Run: %d, Fold: %d\" % (run+1, fold+1))\n",
    "        path = \"%s/Run%d/Fold%d\" % (config.feat_folder, run+1, fold+1)\n",
    "\n",
    "        #########################\n",
    "        ## get word count feat ##\n",
    "        #########################\n",
    "        for feat_name in feat_names:\n",
    "            X_train = dfTrain[feat_name].values[trainInd]\n",
    "            X_valid = dfTrain[feat_name].values[validInd]\n",
    "            with open(\"%s/train.%s.feat.pkl\" % (path, feat_name), \"wb\") as f:\n",
    "                pickle.dump(X_train, f)\n",
    "            with open(\"%s/valid.%s.feat.pkl\" % (path, feat_name), \"wb\") as f:\n",
    "                pickle.dump(X_valid, f)\n",
    "print(\"Done.\")\n",
    "\n",
    "\n",
    "print(\"For training and testing...\")\n",
    "path = \"%s/All\" % config.feat_folder\n",
    "## use full version for X_train\n",
    "extract_feat(dfTest)\n",
    "for feat_name in feat_names:\n",
    "    X_train = dfTrain[feat_name].values\n",
    "    X_test = dfTest[feat_name].values\n",
    "    with open(\"%s/train.%s.feat.pkl\" % (path, feat_name), \"wb\") as f:\n",
    "        pickle.dump(X_train, f, -1)\n",
    "    with open(\"%s/test.%s.feat.pkl\" % (path, feat_name), \"wb\") as f:\n",
    "        pickle.dump(X_test, f, -1)\n",
    "\n",
    "## save feat names\n",
    "print(\"Feature names are stored in %s\" % feat_name_file)\n",
    "## dump feat name\n",
    "dump_feat_name(feat_names, feat_name_file)\n",
    "\n",
    "print(\"All Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
