{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load preprocess.py\n",
    "\n",
    "\"\"\"\n",
    "__file__\n",
    "\n",
    "    preprocess.py\n",
    "\n",
    "__description__\n",
    "\n",
    "    This file preprocesses data.\n",
    "\n",
    "__author__\n",
    "\n",
    "    Chenglong Chen\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nlp_utils import clean_text, pos_tag_text\n",
    "sys.path.append(\"../\")\n",
    "from param_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "Done.\n",
      "Pre-process data...\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "## Load Data ##\n",
    "###############\n",
    "print(\"Load data...\")\n",
    "\n",
    "dfTrain = pd.read_csv(config.original_train_data_path).fillna(\"\")\n",
    "dfTest = pd.read_csv(config.original_test_data_path).fillna(\"\")\n",
    "# number of train/test samples\n",
    "num_train, num_test = dfTrain.shape[0], dfTest.shape[0]\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "\n",
    "######################\n",
    "## Pre-process Data ##\n",
    "######################\n",
    "print(\"Pre-process data...\")\n",
    "\n",
    "## insert fake label for test\n",
    "dfTest[\"median_relevance\"] = np.ones((num_test))\n",
    "dfTest[\"relevance_variance\"] = np.zeros((num_test))\n",
    "\n",
    "## insert sample index\n",
    "dfTrain[\"index\"] = np.arange(num_train)\n",
    "dfTest[\"index\"] = np.arange(num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "## one-hot encode the median_relevance\n",
    "for i in range(config.n_classes):\n",
    "    dfTrain.loc[:,\"median_relevance_%d\" % (i+1)] = 0\n",
    "    dfTrain.loc[:,\"median_relevance_%d\" % (i+1)][dfTrain.loc[:,\"median_relevance\"]==(i+1)] = 1\n",
    "    \n",
    "## query ids\n",
    "qid_dict = dict()\n",
    "for i,q in enumerate(np.unique(dfTrain[\"query\"]), start=1):\n",
    "    qid_dict[q] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert query id\n",
    "# dfTrain[\"qid\"] = map(lambda q: qid_dict[q], dfTrain[\"query\"])\n",
    "# dfTest[\"qid\"] = map(lambda q: qid_dict[q], dfTest[\"query\"])\n",
    "dfTrain[\"qid\"] = list(map(lambda q: qid_dict[q], dfTrain[\"query\"]))\n",
    "dfTest[\"qid\"] = list(map(lambda q: qid_dict[q], dfTest[\"query\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\Ian\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/65497012.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/65516012.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/6552101\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/65527\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januarya/14146012.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "## clean text\n",
    "clean = lambda line: clean_text(line, drop_html_flag=config.drop_html_flag)\n",
    "dfTrain = dfTrain.apply(clean, axis=1)\n",
    "dfTest = dfTest.apply(clean, axis=1)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save data...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n## pos tag text\\ndfTrain = dfTrain.apply(pos_tag_text, axis=1)\\ndfTest = dfTest.apply(pos_tag_text, axis=1)\\nwith open(config.pos_tagged_train_data_path, \"wb\") as f:\\n    pickle.dump(dfTrain, f, -1)\\nwith open(config.pos_tagged_test_data_path, \"wb\") as f:\\n    pickle.dump(dfTest, f, -1)\\nprint(\"Done.\")\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############\n",
    "## Save Data ##\n",
    "###############\n",
    "print(\"Save data...\")\n",
    "import dill\n",
    "with open(config.processed_train_data_path, \"wb\") as f:\n",
    "#     pickle.dump(dfTrain, f)\n",
    "    dill.dump(dfTrain, f)\n",
    "with open(config.processed_test_data_path, \"wb\") as f:\n",
    "#     pickle.dump(dfTest, f)\n",
    "    dill.dump(dfTrain, f)\n",
    "    \n",
    "print(\"Done.\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## pos tag text\n",
    "dfTrain = dfTrain.apply(pos_tag_text, axis=1)\n",
    "dfTest = dfTest.apply(pos_tag_text, axis=1)\n",
    "with open(config.pos_tagged_train_data_path, \"wb\") as f:\n",
    "    pickle.dump(dfTrain, f, -1)\n",
    "with open(config.pos_tagged_test_data_path, \"wb\") as f:\n",
    "    pickle.dump(dfTest, f, -1)\n",
    "print(\"Done.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
