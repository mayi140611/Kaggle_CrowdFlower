{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load genFeat_id_feat.py\n",
    "\n",
    "\"\"\"\n",
    "__file__\n",
    "\n",
    "    genFeat_id_feat.py\n",
    "\n",
    "__description__\n",
    "\n",
    "    This file generates the following features for each run and fold, \n",
    "    and for the entire training and testing set.\n",
    "\n",
    "        1. one-hot encoding of query ids (qid)\n",
    "\n",
    "__author__\n",
    "\n",
    "    Chenglong Chen < c.chenglong@gmail.com >\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "# import cPickle\n",
    "import dill\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "sys.path.append(\"../\")\n",
    "from param_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## config\n",
    "id_names = [ \"qid\" ]\n",
    "\n",
    "###############\n",
    "## Load Data ##\n",
    "###############\n",
    "## load data\n",
    "with open(config.processed_train_data_path, \"rb\") as f:\n",
    "    dfTrain = dill.load(f)\n",
    "with open(config.processed_test_data_path, \"rb\") as f:\n",
    "    dfTest = dill.load(f)\n",
    "## load pre-defined stratified k-fold index\n",
    "with open(\"%s/stratifiedKFold.%s1.pkl\" % (config.data_folder, config.stratified_label), \"rb\") as f:\n",
    "        skf = pickle.load(f, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Generate id features...\n",
      "For cross-validation...\n",
      "Run: 1, Fold: 1\n",
      "[ 0  1  3  4  6  7  8 10 11 13]\n",
      "[ 2  5  9 12 14 20 21 22 23 28]\n",
      "Run: 1, Fold: 2\n",
      "[ 2  4  5  7  9 10 11 12 14 17]\n",
      "[ 0  1  3  6  8 13 15 16 18 24]\n",
      "Run: 1, Fold: 3\n",
      "[ 0  1  2  3  5  6  8  9 12 13]\n",
      "[ 4  7 10 11 17 19 25 29 34 35]\n",
      "Run: 2, Fold: 1\n",
      "[ 1  3  5  6  7  8  9 10 11 13]\n",
      "[ 0  2  4 12 17 18 22 28 32 33]\n",
      "Run: 2, Fold: 2\n",
      "[ 0  2  3  4 12 15 16 17 18 22]\n",
      "[ 1  5  6  7  8  9 10 11 13 14]\n",
      "Run: 2, Fold: 3\n",
      "[ 0  1  2  4  5  6  7  8  9 10]\n",
      "[ 3 15 16 24 26 27 31 34 35 40]\n",
      "Run: 3, Fold: 1\n",
      "[ 1  3  4  5  6  8  9 10 11 13]\n",
      "[ 0  2  7 12 14 17 19 23 24 25]\n",
      "Run: 3, Fold: 2\n",
      "[ 0  2  4  5  6  7  8 12 13 14]\n",
      "[ 1  3  9 10 11 16 18 20 30 31]\n",
      "Run: 3, Fold: 3\n",
      "[ 0  1  2  3  7  9 10 11 12 14]\n",
      "[ 4  5  6  8 13 15 21 22 32 35]\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "## Generate Features ##\n",
    "#######################\n",
    "print(\"==================================================\")\n",
    "print(\"Generate id features...\")\n",
    "\n",
    "print(\"For cross-validation...\")\n",
    "for run in range(config.n_runs):\n",
    "    ## use 33% for training and 67 % for validation\n",
    "    ## so we switch trainInd and validInd\n",
    "    for fold, (validInd, trainInd) in enumerate(skf[run]):\n",
    "        print(\"Run: %d, Fold: %d\" % (run+1, fold+1))\n",
    "        print(validInd[:10])\n",
    "        print(trainInd[:10])\n",
    "        path = \"%s/Run%d/Fold%d\" % (config.feat_folder, run+1, fold+1)\n",
    "\n",
    "        #################\n",
    "        ## get id feat ##\n",
    "        #################\n",
    "        for id_name in id_names:\n",
    "            lb = LabelBinarizer(sparse_output=True)\n",
    "#             lb = LabelBinarizer()\n",
    "            X_train = lb.fit_transform(dfTrain.iloc[trainInd][id_name])\n",
    "            X_valid = lb.transform(dfTrain.iloc[validInd][id_name])\n",
    "            with open(\"%s/train.%s.feat.pkl\" % (path, id_name), \"wb\") as f:\n",
    "                pickle.dump(X_train, f)\n",
    "            with open(\"%s/valid.%s.feat.pkl\" % (path, id_name), \"wb\") as f:\n",
    "                pickle.dump(X_valid, f)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training and testing...\n",
      "Done.\n",
      "All Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"For training and testing...\")\n",
    "path = \"%s/All\" % config.feat_folder\n",
    "## use full version for X_train                \n",
    "for id_name in id_names:\n",
    "    X_train = lb.fit_transform(dfTrain[id_name])\n",
    "    X_test = lb.transform(dfTest[id_name])\n",
    "    with open(\"%s/train.%s.feat.pkl\" % (path, id_name), \"wb\") as f:\n",
    "        pickle.dump(X_train, f, -1)\n",
    "    with open(\"%s/test.%s.feat.pkl\" % (path, id_name), \"wb\") as f:\n",
    "        pickle.dump(X_test, f, -1)\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"All Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
